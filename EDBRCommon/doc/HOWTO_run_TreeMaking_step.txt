
Instructions for running the third step of the analysis:
starting from the cmgTuple produced at the second step (see "doc/HOWTO_run_cmgTuple_step.txt"),
copy the contents them in plain ROOT TTrees.



=== GENERAL comments ===

*) the example cfg is ExoDiBosonResonances/EDBRCommon/test/analyzerEDBR_zz2l2j_tpl.py

*)the analyzer itself is in ExoDiBosonResonances/EDBRCommon/plugins/AnalyzerEDBR.h

*) the final TTree will have for each event, the general info (run and event number,
# of vertices, MET...) and the number of candidates corresponiding to the collections
you specify in the cfg. For each event, there will be a set of branches storing
std::vector with informaitons on the candidates and the associated Z, leptons and jets.
The size of the vectors in the branch is given by the # of candidates, hence it changes
event-by-event.


=== RUNNING STAND-ALONE ===

Take the template cfg EDBRCommon/test/analyzerEDBR_zz2l2j_tpl.py and edit it
according to your needs: decomment the suorce module, add the list of cmgTuples
that you want to process, replace all over the file the tag '<SAMPLE>' with
the label of the sample that you want to process. Make sure that the number
of generated events and the cross section is the correct one. Set the boolean 
'processFullSel' to true if you want to make the trees with the collecitons
passing the final selections (otherwise it uses the default collections passing the
preselection cuts). For data,
Ngen and xsec don't matter (we don't use them in the end) but set them both
to one, just to make sure.

Other important tips on how to steer the module:

*) In the module calling the plugin AnalyzerEDBR, you must give the name
of the collections that you want to use. Refer to ExoDiBosonResonances/EDBRCommon/doc/Summary_Collections.pdf
for more informations. 

*) if you want to check if some HLT trigger slots have been fired or not,
add the string with the names in the parameter "triggerNames".
 
*) make it run:  

cmsRun analyzerEDBR_zz2l2j_cfg.py 


=== RUNNING WITH SCRIPTS ===

1) prepare a list of cmgTuples and save it in a cff file in the directory
ExoDiBosonResonances/EDBRCommon/python/datasets/

The name of this cff should follow the following format:
cmgTuple_<LABEL>_cff.py

2) move to EDBRCommon/test/ 

3) Open the  template EDBRCommon/test/analyzerEDBR_zz2l2j_tpl.py and make
sure that the settings are correct (see previous paragraph of these instructions).
In particular, if you want to process a MC sample make sure that Ngen and xsec
are set to the right values by adding one more block in the if statement:

##############
elif "<SAMPLE>"== "<---> PUT YOUR MC SAMPLE LABEL HERE <--->" :
    process.ANEDBR.Ngen=cms.uint32(2500000)
    process.ANEDBR.xsec=cms.double(32.9)
##############

4) default is to fill the TTrees with the variables from the collections
passing just the pre-selection cuts. If you want to fill with the 
collection of X->VV passing the full selection, in analyzerEDBR_zz2l2j_tpl.py
set to True the variable called 'processFullSel'. Change the name
of the collection if you want the events in the signal or the sidebands.

5) The default is for the ZZ analysis. For the WW some hand corrections
are needed.
    i) in EDBRCommon/test/analyzerEDBR_zz2l2j_tpl.py
       a) change VType=cms.string("W")
	   b) change HLTPaths = cms.vstring("cmgEDBRWWEle","cmgEDBRWWMu")
   ii) go in EDBRCommon/plugins/AnalyzerEDBR.cc and comment the block of lines

//comment these for X->WW analysis
	   typedef  cmg::DiElectronSingleJetEDBR cmgEleSingleJetEDBR ;
	   typedef  cmg::DiMuonSingleJetEDBR     cmgMuSingleJetEDBR  ;
	   typedef  cmg::DiElectronDiJetEDBR     cmgEleDiJetEDBR  ;
	   typedef  cmg::DiMuonDiJetEDBR     cmgMuDiJetEDBR  ;

and de-comment the typedefs immediately below.

	
6) open run_AnalyzerEDBR.sh and edit the fields with the paths, 
in particular $MYWORKAREA, $CFGAREA and $OUTDIR . The output TTrees 
and the logs will be saved in $OUTDIR
Change type="full" or "presel" denpending on processFullSel=True or False in analyzerEDBR_zz2l2j_tpl.py 

7) open submit_AnalyzerEDBR.sh and add in the array SampleName
all the samples that you want to process. It is important that the
labels are consistent across all the files (submit_AnalyzerEDBR.sh,
analyzerEDBR_zz2l2j_tpl.py and the cmgTuple list in ExoDiBosonResonances/EDBRCommon/python/datasets/)

8) just execute:
./submit_AnalyzerEDBR.sh

If you want to run XWW analysis, do
./submit_AnalyzerEDBR_xww.sh

the jobs will be submitted to the LXBatch system, one for each sample.

NOTE!!! remember to run cmsenv before submitting the jobs

9) you can check if you trees are correctly produced.
modify the path of your trees in ExoDiBosonResonances/EDBRCommon/test/check_trees.sh,
and then 
./check_trees.sh
This script will look for "1 fileAction           -s file_close  " in the logs.
If not found, it will give out a warnig.


10) NEW SCRIPT to submit and check trees

TO RUN:
Modify in submit_new_xww.sh, the SampleList, type, outdir and queue.
For ZZ the only difference is the samplelist.
Then
./submit_new_xww.sh

Then in yourtreepath/logs, there will be a folder for each sample.
In the folder there will be
1. cfg file
2. shell to be submitted
3. outputlog
4. LSF output


TO CHECK:
Modify in check_new.sh the TREEDIR. Keep RESUB=0 in the first check.
then ./check_new.sh
For each sample dir in the log, it will first search for the corresponding root file in the tree folder.
If found , it will check the log. If not found, it will tell you.
Then you can check the logs to find the problem.
At last you change RESUB=1 to resubmit them.


11) Another new script to submit the trees  --------- Recommended

There is a new script to submit the trees, from which you can decide how many files to run in one job.

The scripts are
 
ExoDiBosonResonances/EDBRCommon/test/submit_split.sh
ExoDiBosonResonances/EDBRCommon/test/check_split.sh
ExoDiBosonResonances/EDBRCommon/test/cmsBatch.py

TO SUBMIT:
Edit submit_split.sh, note you have an option of how many files to run in each job. The default is 10 here. Then
./submit_split.sh

TO CHECK:
Edit check_split.sh, set the treedir and RESUB=0, MERGE=0, MERGESAMPLE=0. Then
./check_split.sh
It will tell you if you are missing some root files or in some logs there are things incorrect. 
Then you set RESUB=1 and run it again to resubmit failed jobs.
After everything is fine you can set MERGE=1 to merge the output of the jobs.
For WW, you can then set MERGE=0, MERGESAMPLE=1, to merge similar samples to
one root file.



