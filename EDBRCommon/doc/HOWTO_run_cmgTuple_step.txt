
Instructions for running the second step of the analysis:
starting from already made PAT-tuples, run the analysis code
that applieas ALL selections, builds di-boson resonances (informally 
called "EDBR")and writes the collections in a cmgTuple (edm-tuple with 
objects belinging to the CMG data format).



=== INPUTS and STEERING ===

*) the main cfg is ExoDiBosonResonances/EDBRCommon/prod/EDBR_main_cfg.py

*) the file ExoDiBosonResonances/EDBRCommon/python/cmdLine.py contains some
steering parameters used by EDBR_main_cfg.py for deciding what to run and
how. They can be changed via command line giving more flexibility 
to the system.

*) the PU-rew histograms are in ExoDiBosonResonances/EDBRCommon/data/
and they are used in ExoDiBosonResonances/EDBRCommon/python/PUweights_cff.py

*) many collections of objects are created: electrons, muons, jets at
different stage of selection, similar thing for V bosons and for EDBR
candidates. A full list with explanation of meanings and location of
files where they are created is in
ExoDiBosonResonances/EDBRCommon/doc/Summary_Collections.pdf

*) the collections of objects saved in the final cmgTuple are specified
in ExoDiBosonResonances/EDBRCommon/python/outputModules_cff.py


=== RUNNING ===

These instructions are good for running test jobs
and for showing the basic idea of the analysis framework.
For mass productions, see the next section "Running with scripts".

1) Prepare a list of input PAT-tuples following the example of
ExoDiBosonResonances/EDBRCommon/python/datasets/test_RSGZZ600_cff.py

and copy it in the directory ExoDiBosonResonances/EDBRCommon/python/datasets/

2) Specify output contents and output file name in outputModules_cff.py

3) make it run:  

cd prod/
cmsRun EDBR_main_cfg.py

4) you can steer from command line several options. 
For example you can switch from a file list to another in this way :
cmsRun EDBR_main_cfg.py infile="newFileList_cff"

If you want to run on dat instead of MC:
cmsRun EDBR_main_cfg.py mcordata=DATASE/DATASM/DATAELE/DATAMU

If you want to store only certain products:
cmsRun EDBR_main_cfg.py content=gen
(for knowing what are the possibilities and what they are 
actually doing, look in ExoDiBosonResonances/EDBRCommon/python/outputModules_cff.py)

You can change many options at the same time
cmsRun EDBR_main_cfg.py maxEvents=1234 infile="newFileList_cff" selection="presel" mcordata=DATA json="jsonOfToday.json"

A full list of options allowed is in 
ExoDiBosonResonances/EDBRCommon/python/cmdLine.py 
FWCore/ParameterSet/python/VarParsing.py


=== RUNNING WITH SCRIPTS ===

When you have many PAT-tuples in input, it is more convenient to use
a set of scripts provided by the CMG that split the job in many bunches
and submit them to the LXBatch system with bsub.

1)  Prepare a list of input PAT-tuples following the example of
ExoDiBosonResonances/EDBRCommon/python/datasets/test_RSGZZ600_cff.py
and copy it in the directory ExoDiBosonResonances/EDBRCommon/python/datasets/

Lists for data should be called in the following format:
data_<LABEL>_cff.py

while for MC the format is 
summer12_<LABEL>_cff.py

LABEL is a tag that you assign to the sample: it can be something like WJetsPt100 or
TTbar or SingleMuJul13, for example.

If your PAT-tuples are in a directory on eos you can use these commands
from the command line for having the full list of files in the correct
format

-$> SAMPLEDIR=/store/group/phys_exotica/leptonsPlusJets/ExoDiBosonResonances/productionv1/PAT/<path_to_PATtuples>/
-$> for file in $( cmsLs $SAMPLEDIR | awk '{print $5}' ); do echo \ \ \ \ \ \ \'${file}\'\, >> list_PATtuples_tmp.txt;done

and then copy the content of list_PATtuples_tmp.txt into the list in ExoDiBosonResonances/EDBRCommon/python/datasets/summer12_<LABEL>_cff.py

There is a script to make such cff files.
Change the path and sample names in ExoDiBosonResonances/EDBRCommon/python/datasets/makeCffInputFiles_ls.sh,
and run with
./makeCffInputFiles_ls.sh
A new folder with your username will be generated. The cff files will be ready
in this folder.

2) Specify output contents and output file name in EDBRCommon/python/outputModules_cff.py

3) edit ExoDiBosonResonances/EDBRCommon/prod/run_cmgTuple_prod.sh:

   - in the arrays SAMPLE_Run2012A, SAMPLE_Run2012B, SAMPLE_MC1, SAMPLE_MC2
     write the LABEL of the lists of PAT-tuples you want to process.
   - if you don't want to process a certain type of data, just leave the array empty
   - write the output directory on eos in OUTPATHBASE, OUTPATHDATA and OUTPATHMC
   - there are as many loops as arrays with datasets to process. For each of the
     loops, choose how many PAT-tuples you want to bunch together. If you have 
     a total of 1200 PAT-files and you choose NFILES=20, it will split the job in
     1200/20= 60 parallel jobs and submit 60 jobs to LXB
   - for each loop, choose the LXB queue
   - for each loop, set the options of your analyzer job just as explained in the
     section above  
   - in the loops of the data, set the correct JSON file

4) run it with
  -$> cd ExoDiBosonResonances/EDBRCommon/prod/
  -$> ./run_cmgTuple_prod.sh

  if you want to run on XWW channel, do
	  ./run_cmgTuple_prod_XWW.sh

5) you can check if some parallel job had problems ending with an exception 
running the script 

-$> ./check_cmgTupleJob.sh MC  ### use DATA for looping over data samples

If some job is listed of having being failed, look for more informations
in the corresponding log file. The script simply parses the log file and
greps for the workd 'exception' . 

You can use the option 
RESUB=1
to resubmit problematic jobs.